---
title: "HDA Exam"
author: Matilde Castelli
output:
  rmdformats::robobook:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

```{r echo = FALSE, warning = FALSE, comment = FALSE, include = FALSE}
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggpubr)
library(gtsummary)
library(tidyverse)
library(finalfit)
library(naniar)
library(mice)
library(reshape2)
library(lattice)
library(caret)
library(Hmisc)
library(rms)
library(pROC)
library(corrplot)
#library(broom.helpers)
library(survival)
library("survminer")
library(corrplot)
library(broom)
library(splines)
library(DynNom)
library(survival)
library(xgboost)
library(Matrix)
library(data.table)
library(Ckmeans.1d.dp)

```

# Introduction

* **DATA** come from an *observational* study
* **AIM** of the project: prediction model for the 10-year risk of death of individuals considering
+ demographic and socioeconomic charateristics
+ clinical parameters
+ biomarkers 



# Question 1: Descriptive Table
**Build a descriptive table, comparing patients with the event death (within 10 years) versus patients without the event in that time frame. Insert also a column with the total population descriptive statistics. Comment about percentages of missing data in the candidate predictors.**

```{r echo = FALSE, warning = FALSE, comment = FALSE, include = FALSE}
#load dataset
survey <- read.csv(file = 'Survey.csv')
```

## 1.1 Format variables
```{r fig.width=20,fig.height=10}
#explore the type of variables
str(survey)
```
Some variables coded as `int` are actually categorical, thus I proceed to recode them as factor.
```{r}
#rename time variable to avoid conflicts
names(survey)[names(survey) == "time"] <- "time_death"

# recode categoric variable as factor
categoric_vars<-c('Race','Sex','status','death')
survey[,categoric_vars]<-lapply(survey[,categoric_vars], as.factor)
numeric_vars<- survey %>% dplyr::select(-(all_of(categoric_vars))) %>% colnames()

#assign labels in order to make easier the comparisons
survey$Race=factor(survey$Race,
                           labels = c("White",
                           "afro-american",
                            "other"))
survey$Sex = factor(survey$Sex, labels = c("male", "female"))
str(survey)
```

## 1.2 Visualization 

Sometimes visualize data can help to understand better their meaning. 

### Categorical variables

```{r fig.width=20,fig.height=8}

# # categorical variables
# barR <- ggplot(data = survey, aes(x=Race, fill = "Race")) + 
#   geom_bar(width = 0.6) + xlab("Race")+
#   ggtitle("Race") +  
#   scale_fill_manual(values=c("Orange", "#bb44f0", "#45ADA8"))+theme_classic()
# 
# barS <- ggplot(data = survey, aes( x =status, fill = "status")) + 
#   geom_bar(width = 0.6) + 
#   xlab("Status") +ylab("Count")+
#   ggtitle("Status") + 
#   scale_fill_manual(values=c("#bb44f0"))+theme_classic()
# #stacked.barS
# 
# barSe <- ggplot(data = survey, aes( x =Sex, fill = "Sex")) + 
#   geom_bar(width = 0.6) + 
#   xlab("Sex") +ylab("Count")+
#   ggtitle("Sex") +
#   scale_fill_manual(values=c("#45ADA8")) + theme_classic()
# #stacked.barSe
# 
# tot.p <- grid.arrange(barR,barS,barSe, ncol = 3) 

```


Let's see how data distributed among the variable `death`.

```{r fig.width=20,fig.height=8}
windowsFonts(A = windowsFont("Arvo"))
# categorical variables
# consider the relative frequency to have a better understanding

# stacked.barR <- ggplot(data = survey, aes( x =Race, fill = death)) + 
#   geom_bar(position = "fill") + 
#   xlab("Race") +ylab("Relative Frequency")+
#   ggtitle("Deaths per Race") +  
#   scale_fill_manual(values=c("Orange", "#bb44f0"))+theme_classic()
# #stacked.barR
# 
# stacked.barS <- ggplot(data = survey, aes( x =status, fill = death)) + 
#   geom_bar(position = "fill") + 
#   xlab("Status") +ylab("Relative Frequency")+
#   ggtitle("Deaths per status") + 
#   scale_fill_manual(values=c("Orange", "#bb44f0"))+theme_classic()
# #stacked.barS
# 
# stacked.barSe <- ggplot(data = survey, aes( x =Sex, fill = death)) + 
#   geom_bar(position = "fill") + 
#   xlab("Sex") +ylab("Relative Frequency")+
#   ggtitle("Deaths per Sex") +
#   scale_fill_manual(values=c("Orange", "#bb44f0")) + theme_classic()
# #stacked.barSe
# 
# tot.p <- grid.arrange(stacked.barR,stacked.barS, stacked.barSe, ncol = 3) 

```

### Continous variables


Since some variables appear to be positively skewed we apply square root or log transformation to make them more normally-distributed.

```{r comment = FALSE, warning = FALSE}
#transformation of Skewed variables

transform_sqrt<-c("Pulse.pressure", "Serum.Iron", "Poverty.index")
transform_log <-c("BMI", "Serum.Cholesterol","Red.blood.cells","White.blood.cells", "Sedimentation.rate")
survey_trans<-survey
survey_trans[,transform_log]<-lapply(survey[,transform_log], log)
survey_trans[,transform_sqrt]<-lapply(survey[,transform_sqrt], sqrt)


# for (var in c(transform_log, transform_sqrt)){
# 
#   hist.p<-gghistogram(survey, x = var, y = "..count..", add = "mean",bins = 20, fill = "orange", rug = TRUE, color = "orange", title = "Original")+theme_classic()
# 
#   hist.t<-gghistogram(survey_trans, x = var, y = "..count..", add = "mean", bins = 20, fill = "orange",rug = TRUE, color = "Orange", title = "Transformed")+theme_classic()
#   tot.p <- grid.arrange(hist.p, hist.t, ncol = 2)
# 
# }

```

```{r echo = FALSE}
colnames(survey_trans)[which(names(survey_trans) == "Pulse.pressure")] <- "Pulse.pressure.sqrt"
colnames(survey_trans)[which(names(survey_trans) == "Serum.Iron")] <- "Serum.Iron.sqrt"
colnames(survey_trans)[which(names(survey_trans) == "Poverty.index")] <- "Poverty.index.sqrt"

colnames(survey_trans)[which(names(survey_trans) == "BMI")] <- "BMI.log"
colnames(survey_trans)[which(names(survey_trans) == "Serum.Cholesterol")] <- "Serum.Cholesterol.log"
colnames(survey_trans)[which(names(survey_trans) == "Red.blood.cells")] <- "Red.blood.cells.log"
colnames(survey_trans)[which(names(survey_trans) == "White.blood.cells")] <- "White.blood.cells.log"
colnames(survey_trans)[which(names(survey_trans) == "Sedimentation.rate")] <- "Sedimentation.rate.log"
```



Let's see how data distributed among the variable `death`.

```{r comment = FALSE, warning = FALSE}
# for (var in numeric_vars){
# 
#   hist.p<-gghistogram(survey, x = var, y = "..density..", add = "median", bins = 20, rug = TRUE,fill = "death", add_density = TRUE, palette = c("Orange", "#bb44f0"))
# 
#   bx.p <- ggboxplot(survey, x="death", y=var, ylab = var, color ="death" ,palette = c("Orange", "#bb44f0"))
#   tot.p <- grid.arrange(bx.p,hist.p, ncol = 2)
# 
# }
```

## 1.3 Descriptive table

A first rough overview on descriptive statistics can be given by function `summary()`

```{r}
summary(survey)
```
From this `summary`we can already notice that just one variable has missing values: `Systolic.BP`.

Let's see the descriptive statistics in a fancier way, comparing the patients with the event and those without it, adding also a column with total population's statistics.

```{r warning =FALSE, comment = FALSE}
# Descriptive statistics of patients'characteristics by outcome
# survey %>% 
#   dplyr::select(all_of(numeric_vars), all_of(categoric_vars)) %>%
#   tbl_summary(by = death,
#               type = all_continuous() ~ "continuous2",
#               statistic = all_continuous() ~ c(
#                                      "{mean} ({sd})",         
#                                      "{median} ({p25}, {p75})", #median with 1th-3th percentiles
#                                      "{min}, {max}",
#                                      "{N_miss} ({p_miss} %)"),
#               missing = "no") %>% 
#   add_overall() %>% 
#   add_p() %>%
#   bold_labels()
```

As we said, just the variable **Systolic.BP**, referring to the systolic blood pressure, has Missing Values. The percentage of missing values is > 5%, indeed it has 20% of missing values. This implies that we cannot ignore them but instead we have to handle them.   

# Question 2: Missing Values
**You will probably note that one variable has a non-negligible rate of missing values. Do you think that the missing values are completely at random, at random or not at random?**

Let's see some statistical descriptive about the distribution among missing and non missing.
```{r echo= FALSE}
survey_trans$systolic_test <- factor(ifelse(is.na(survey_trans$Systolic.BP),"missing","non-missing"))

```

```{r}
#Adding a categorical variable indicating missing and non missing Systolic.BP values for each row

survey$systolic_test <- factor(ifelse(is.na(survey$Systolic.BP),"missing","non-missing"))
# 
# # Descriptive statistics of patients'characteristics by outcome
# df = subset(survey, select=-Systolic.BP)
# tbl_summary(df, by = systolic_test,
#               type = all_continuous() ~ "continuous2",
#               statistic = all_continuous() ~ c(
#                                       "{mean} ({sd})",         
#                                      "{median} ({p25}, {p75})", #median with percentile
#                                      "{min}, {max}"),
#               missing = "no") %>% 
#   add_overall() %>% 
#   bold_labels()

```
Which type of Missing do we have?
The first approach is to make a graphical comparison between the observed and missing data in in each variable with boxplots and overlapping histograms for numeric variables.
If the missing values are **Missing Completely at Random** we will expect that the distributions are identical, or at least comparable. Indeed in this case Missing data values do not relate to any other data in the dataset and there is no pattern to the actual values of the missing data themselves.
If the distributions are different, we can have two cases:

- **MAR**: missing data do have a relationship with other variables in the dataset.But, the actual values that are missing are random.
- **MNAR**: The pattern of missingness is related to other variables in the dataset, but in addition, the values of the missing data are not random. Moreover the value of the variable that's missing is related to the reason it's missing.


```{r fig.width=20,fig.height=8,warning = FALSE, comment= FALSE}
#numeric variables
# for (var in numeric_vars){
#   hist.p<-gghistogram(survey, x = var, y ="..density.." ,add = "median", bins = 20, rug = TRUE, fill = "systolic_test",add_density = TRUE, alpha = 0.5,palette = c("Orange", "#bb44f0")) +theme_minimal()
#   bx.p <- ggboxplot(survey, x="systolic_test", y=var, ylab = var, color ="systolic_test",palette = c("Orange", "#bb44f0"))+theme_minimal()
#   tot.p <- grid.arrange(bx.p,hist.p, ncol = 2)
# 
# }


# #categorical variable
# barMR <- ggplot(data = survey, aes( x =Race, fill = systolic_test)) + 
#   geom_bar(position = "fill") + 
#   xlab("Race") +ylab("Relative Frequency")+
#   ggtitle("Missings per Race") + 
#   scale_fill_manual(values=c("Orange", "#bb44f0"))+theme_classic()
#   
# barMS <- ggplot(data = survey, aes( x = Sex, fill = systolic_test)) + 
#   geom_bar(position = "fill") + 
#   xlab("Sex") +ylab("Relative Frequency")+
#   ggtitle("Missings per Sex") +  
#   scale_fill_manual(values=c("Orange", "#bb44f0"))+theme_classic()
# 
# barMD <- ggplot(data = survey, aes( x = death, fill = systolic_test)) + 
#   geom_bar(position = "fill") + 
#   xlab("Death") +ylab("Relative Frequency")+
#   ggtitle("Missings per death") +  
#   scale_fill_manual(values=c("Orange", "#bb44f0"))+theme_classic()
# 
# barMSt <- ggplot(data = survey, aes( x = status, fill = systolic_test)) + 
#   geom_bar(position = "fill") + 
#   xlab("status") +ylab("Relative Frequency")+
#   ggtitle("Missings per status") +  
#   scale_fill_manual(values=c("Orange", "#bb44f0"))+theme_classic()
# 
# tot.p <- grid.arrange(barMR,barMS, barMSt, barMD, ncol = 2, nrow = 2) 
```

From these plots we can notice that missingness in Systolic.BP is not completely at random. On the contrary the missingness is related to other variables. They drastically differ by Age and are slightly related to higher values of Pulse.Pressure, Sedimentation.rate and lower value of Poverty.index. Moreover missigness is more present in patients that died within 10 years or experimented the event before the end of the study.

We can assess if the difference between observed and missing distributions is statistically significant performing `Kruskal-Wallis` test on continous data. In this tests:

- $H_0$: indicates equivalence between the two distributions (two sample are from identical population)
- $H_a$: the difference between distributions is statistically significant.

```{r}
#kruskal-wallis
cont<- c("Age", "Pulse.pressure", "Sedimentation.rate", "Poverty.index")
categ<-c("death", "status", "Sex")

kruskal.test(Age ~ systolic_test, data = survey)
kruskal.test(Pulse.pressure ~ systolic_test, data = survey)
kruskal.test(Sedimentation.rate ~ systolic_test, data = survey)
kruskal.test(Poverty.index ~ systolic_test, data = survey)

```
For each test there is evidence to reject the null hypothesis since p-value << 0.05. Thus, we can conclude that there are differences between observed and missing distributions and so definitely missings are not MCAR. We have to choose between MAR and MNAR. MNAR would imply that there is a physiological reason that make the Systolic.BP measurement depend on Age, pressure or sedimentation, while from this test results only an association, relation. Since this hypothesis requires more clinical knowledge and we can't have the opinion of a specialist, nevertheless we do not know how the study and population were carrried out and chosen, I choose to consider the missings as **Missing at Random.**
We can only guess why missings are related to those independent variables. Maybe clinicians didn't want to undergo severely ill old patients to other diagnostic tests
Then we cannot ignore them but we have to find a way to handle these missings. Furthermore people without BP measures apparently have higher mortality rates (percentage of missings is higher in patients died within 10 years ) suggesting that eliminating the incomplete data will overestimate the true survival of the cohort.

Since for each patient we have other two measurement related to blood pressure, Pulse.Pressure and Diastolic pressure, we can assume that imputation of missing using that information could be a reasonable idea. But let's verify if there is actually a correlation between these variables. We can plot graphically a heatmap based on Pearson correlation.

## Correlation matrix
```{r fig.width=20,fig.height=8,warning = FALSE, comment= FALSE}

# categoric_vars<-c('Race','Sex','status','death', 'time_death', 'systolic_test')
# numeric_vars<- survey_trans %>% dplyr::select(-(all_of(categoric_vars))) %>% colnames()
# 
# cormat<- round(x = cor(select(survey_trans, numeric_vars), use="complete.obs"), digits = 2)
# melted_cormat <- reshape2::melt(cormat)
# 
#   # Get upper triangle of the correlation matrix
#   get_upper_tri <- function(cormat){
#     cormat[lower.tri(cormat)]<- NA
#     return(cormat)
#   }
#   upper_tri <- get_upper_tri(cormat)
#   # Melt the correlation matrix
# 
# melted_cormat <- melt(upper_tri, na.rm = TRUE)
# # Heatmap
# 
# reorder_cormat <- function(cormat){
# # Use correlation between variables as distance
# dd <- as.dist((1-cormat)/2)
# hc <- hclust(dd)
# cormat <-cormat[hc$order, hc$order]
# }
# 
# # Reorder the correlation matrix
# cormat <- reorder_cormat(cormat)
# upper_tri <- get_upper_tri(cormat)
# # Melt the correlation matrix
# melted_cormat <- reshape2::melt(upper_tri, na.rm = TRUE)
# # Create a ggheatmap
# ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
#  geom_tile(color = "white")+
#  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
#    midpoint = 0, limit = c(-1,1), space = "Lab", 
#     name="Pearson\nCorrelation") +
#   theme_minimal()+ # minimal theme
#  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
#     size = 12, hjust = 1))+
#  coord_fixed()
# # Print the heatmap
# ggheatmap+ geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
# theme(
#   axis.title.x = element_blank(),
#   axis.title.y = element_blank(),
#   panel.grid.major = element_blank(),
#   panel.border = element_blank(),
#   panel.background = element_blank(),
#   axis.ticks = element_blank(),
#   legend.justification = c(1, 0),
#   legend.position = c(0.6, 0.7),
#   legend.direction = "horizontal")+
#   guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
#                 title.position = "top", title.hjust = 0.5))
```
As we guessed, the heatmap show the high correlation with Diastolic.BP and Pressure.BP. This suggest that imputation technique such as `MICE`, which internally use regression model and require MAR type, would lead to reasonably accurate results.



## MICE: Data imputation

MICE(Multiple Imputation by Chained Equations). A brief overview on the algorithm:
It reapeats 4 steps till convergence. At each cycle missing data are imputed:

Steps:

1. Mean Imputation

2. Choose the variable with fewer missings, build a regression model to impute that variable using the others as predictors.

3. Replace missings with predictions

4. Move to other variables with missings.

```{r fig.width=15,fig.height=8,warning = FALSE, comment = FALSE}
#used as predictors only the variables that have correlation > 0.25 with Systolic.BP
pred_mat <- quickpred(survey_trans, mincor = 0.25)
imp <- mice(survey_trans, m=10, seed = 1, predictorMatrix = pred_mat) #m = number of datasets generated

#diagnostic plots
densityplot(imp)
bwplot(imp)

```
The `densityplot()` shows that the imputed values of `Systolic.BP` are higher than the observed values.According to `bwplot()` all the dataset produced are equivalent, thus I choose the first.

```{r fig.width=15,fig.height=8,warning = FALSE, comment= FALSE}
survey_mice<-mice::complete(imp,1)

# See the difference using the mean

survey_mean<- survey_trans
survey_mean$Systolic.BP[is.na(survey_mean$Systolic.BP)] <- mean(survey_mean$Systolic.BP, na.rm = TRUE) 
par(mfrow=c(1,2))
boxplot(survey_trans$Systolic.BP, survey_mice$Systolic.BP, 
        names = c("observed", "imputed"), col = c("orange","#bb44f0"), main = "MICE imputation")
boxplot(survey$Systolic.BP, survey_mean$Systolic.BP, 
        names = c("observed", "imputed"), col = c("orange","#bb44f0"), main = "Mean Imputation")


```
The mean imputation seems to reflect better the observed distribution, however it doesn't take into account the relationship with the other variables. Furthermore we saw that The missings in Systolic.BP are related to higher value of Pressure and Diastolic, thus since are strictly correlated the imputation values can be higher.

# Question 3: Univariable Regression
**Perform univariable regression analyses, of all candidate predictors for your model.**

Which regression?

- The focus is on predicting the 10-year risk mortality not the time to event, thus the outcome variable is `death`, a binary variable.
- We do not have to concern about censoring, since the first patient censored is after 10,03 years.

```{r fig.width=15,fig.height=8}
cens<- ggplot(survey_mice, aes(x = time_death, fill = status)) +
  geom_histogram(binwidth = 0.3, position = position_stack(reverse = TRUE))+xlab("Time to death(years)")+
  scale_fill_manual(values=c("Orange", "LightGrey"))+ geom_vline(xintercept = 10, linetype="dashed")+
  ggtitle("Censored patients")+
  theme_classic()
cens

```

Thus I decided to use **Logistic Regression**.
```{r echo = FALSE}
dd <- datadist(survey_mice)
options(datadist="dd")
```


```{r warning = FALSE, comment = FALSE}
# note that here odds ratios are expressing variations by 1-unit on the time, in the summary function we had interquartile range as an effect 

# survey_mice %>% dplyr::select(-c(status, systolic_test)) %>% 
#   tbl_uvregression(method = glm, # glm function
#                  method.args = list(family = binomial),# logistic model
#                  exponentiate = T, # report OR
#                  y=death,# outcome variable
#                  conf.level = 0.95,
#                  pvalue_fun = ~style_pvalue(.x, digits = 3)) %>%
#   bold_labels() %>%
#   bold_p()
```
Considering this univariable regression, assuming that linearity of the effect for each predictors, crude odds ratio result in:

-  no effect between `Poverty.index`, `Serum.Cholesterol`, `Serum.Iron`, `TIBC`, `TS`, `BMI` and the outcome
- a protective effect for `Serum.Albumin`, `Serum.Magnesium`, `being female over male`
- greater risk with increase of `Age`, `Diastolic.BP`, `Red.blood.cells`, `Sedimentation.rate`, `Serum.Protein`, `Systolic.BP`, `White.blood.cells`, `Pulse.pressure`

Let's know explore if linearity is a valid assumption for the effect of each of the predictors:
```{r fig.width=15,fig.height=8}
# # Visual exploration of the linearity of the effect for continuous predictor
# par(mfrow = c(3,3))
# plsmo(survey_mice$Age,survey_mice$death)
# plsmo(survey_mice$Diastolic.BP,survey_mice$death) #little strange
# plsmo((survey_mice$Poverty.index.sqrt),survey_mice$death) #strange
# plsmo(survey_mice$Red.blood.cells.log,survey_mice$death)# U shape
# plsmo((survey_mice$Sedimentation.rate.log),survey_mice$death)
# plsmo(survey_mice$Serum.Albumin,survey_mice$death)
# plsmo(survey_mice$Serum.Cholesterol.log,survey_mice$death)
# plsmo((survey_mice$Serum.Iron.sqrt),survey_mice$death)# little stranve
# plsmo(survey_mice$Serum.Magnesium,survey_mice$death) #little strange
# 
# par(mfrow = c(3,3))
# plsmo(survey_mice$Serum.Protein,survey_mice$death) #strange
# plsmo((survey_mice$Systolic.BP),survey_mice$death)
# plsmo(survey_mice$TIBC,survey_mice$death)
# plsmo(survey_mice$TS,survey_mice$death)
# plsmo((survey_mice$White.blood.cells.log),survey_mice$death)# strange
# plsmo(survey_mice$BMI.log,survey_mice$death)# strange
# plsmo(survey_mice$Pulse.pressure.sqrt,survey_mice$death)
# plsmo(survey_mice$time_death,survey_mice$death)
# plsmo(survey_mice$Age,survey_mice$death)
```

Let's investigate if weird plots are associated with statistically significant non linear effect for the predictors. in order to check this, I used `restricted cubic splines` to interpolate non linear components and then test if these componenets are sttatistically significative looking at the `p-value` and also use the `ANOVA`, where $H_0$ assumes linearity of the effect between log odds of outcome and predictors.

```{r}
# non linearity between predictors and outcome
fit.splines.BMI <-  lrm(death ~ BMI.log , data=survey_mice)
print(fit.splines.BMI)
summary(fit.splines.BMI)
anova(fit.splines.BMI)
fit.splines2 <-  lrm(death ~ Serum.Iron.sqrt , data=survey_mice)
fit.splines2<-lrm(death ~White.blood.cells.log, data=survey_mice)
summary(fit.splines2)
```

```{r}
# non linearity between predictors and outcome
fit.splines.TS <-  lrm(death ~ rcs(TS,4), data=survey_mice)
#print(fit.splines.TS)
#summary(fit.splines.TS)
```

```{r}
# non linearity between predictors and outcome
fit.splines.Protein <-  lrm(death ~ rcs(Serum.Protein,3), data=survey_mice)
#print(fit.splines.Protein)
#summary(fit.splines.Protein)
#anova(fit.splines.Protein)
```

```{r}
# non linearity between predictors and outcome
fit.splines.Mag <-  lrm(death ~ rcs(Serum.Magnesium,3), data=survey_mice)
#print(fit.splines.Mag)
#summary(fit.splines.Mag)
#anova(fit.splines.Mag)
```


```{r}
# non linearity between predictors and outcome
fit.splines.Iron <-  lrm(death ~ rcs(Serum.Iron.sqrt,6), data=survey_mice)
#print(fit.splines.Iron)
#summary(fit.splines.Iron)
#anova(fit.splines.Iron)
```

```{r}
# non linearity between predictors and outcome
fit.splines.Chol <-  lrm(death ~ rcs(Serum.Cholesterol.log,4), data=survey_mice)
#print(fit.splines.Chol)
#summary(fit.splines.Chol)
```

```{r}
# non linearity between predictors and outcome
fit.splines.Red <-  lrm(death ~ rcs(Red.blood.cells.log,3), data=survey_mice)
#print(fit.splines.Red)
#summary(fit.splines.Red)
#anova(fit.splines.Red)
```

```{r}
# non linearity between predictors and outcome
fit.splines.Poverty <-  lrm(death ~ rcs(Poverty.index.sqrt,4), data=survey_mice)
#print(fit.splines.Poverty)
#summary(fit.splines.Poverty)
#anova(fit.splines.Poverty)
```

```{r}
# non linearity between predictors and outcome
fit.splines.Diastolic <-  lrm(death ~ rcs(Diastolic.BP,4), data=survey_mice)
#print(fit.splines.Diastolic)
#summary(fit.splines.Diastolic)
#anova(fit.splines.Diastolic)

```

```{r}
# non linearity between predictors and outcome
fit.splines.Sys <-  lrm(death ~ rcs(Systolic.BP,4), data=survey_mice)
#print(fit.splines.Sys)
#summary(fit.splines.Sys)
#anova(fit.splines.Sys)
```

```{r}
# non linearity between predictors and outcome
fit.splines.Pres <-  lrm(death ~ rcs(Pulse.pressure.sqrt,4), data=survey_mice)
# print(fit.splines.Pres)
# summary(fit.splines.Pres)
# anova(fit.splines.Pres)
```
```{r}
# non linearity between predictors and outcome
fit.splines.TS <-  lrm(death ~ rcs(TS,4), data=survey_mice)
# print(fit.splines.TS)
# summary(fit.splines.TS)
# anova(fit.splines.TS)
```

From these tests result statistically significant the **non-linear** effect for: `Poverty.index`, `Systolic.BP`, `Pressure.pulse`, `Diastolic.BP`, `Red.blood.cells`,`Iron`,`BMI`, `Magnesium`

```{r fig.width=15,fig.height=8, warning = FALSE, comment = FALSE}
#stima effetto della variazione delle covariate sul rischio di morte (su scala log odds)
#stima effetto della variazione delle covariate sul rischio di morte (su scala log odds)

# a<-ggplot(Predict(fit.splines.Poverty), colfill = "Orange")+theme_classic()
# b<-ggplot(Predict(fit.splines.Sys),colfill = "Orange")+theme_classic()
# c<-ggplot(Predict(fit.splines.Pres),colfill = "Orange")+theme_classic()
# d<-ggplot(Predict(fit.splines.Diastolic),colfill = "Orange")+theme_classic()
# e<-ggplot(Predict(fit.splines.Red),colfill = "Orange")+theme_classic()
# f<-ggplot(Predict(fit.splines.Iron),colfill = "Orange")+theme_classic()
# g<-ggplot(Predict(fit.splines.BMI),colfill = "Orange")+theme_classic()
# h<-ggplot(Predict(fit.splines.Mag),colfill = "Orange")+theme_classic()
# i<-ggplot(Predict(fit.splines.Protein), colfill = "Orange")+theme_classic()
# 
# tot.p <- grid.arrange(a,b,c,d,e,f,g,h, i, ncol = 3, nrow = 3) 
```

# Question 4: Multivariable Regression
**Build a multivariable model. Various selection procedures of the candidate predictors could be performed (try different approaches and compare them… we don’t have here the expert’s opinion, therefore the final choice will be based only on statistical evaluations). Comment on the effect estimated for the predictors retained in the final multivariable model**

I fit several models using both implemented algorithms (BACKWARD, STEPWISE,HYBRID) and selection of predictors by hand looking at AIC, statistical significance, log-likelihood ratio test. I will consider here only the 4 best models.

## Backward elimination

### Backward by hand

```{r}
# # Full model considering the non linear effect
# # Full model considering the non linear effect
# fit.multi.lrm<-lrm(death ~ Age+rcs(Diastolic.BP,4)+rcs(Poverty.index.sqrt,4)+Race+ rcs(Red.blood.cells.log,3)+
#                      Sedimentation.rate.log+Serum.Albumin+Serum.Cholesterol.log+ rcs(Serum.Iron.sqrt,6)+rcs(Serum.Magnesium,3)+rcs(Serum.Protein,3)+
#                      Sex+TIBC+TS+White.blood.cells.log+rcs(BMI.log,4)+rcs(Pulse.pressure.sqrt,4) ,data = survey_mice, y=T, x=T)
# print(fit.multi.lrm) #adjusted odds ratio
# s <- summary(fit.multi.lrm)
# 
# fit.multi.glm<-glm(death ~ Age+ns(Diastolic.BP,4)+ns(Poverty.index.sqrt,4)+Race+ ns(Red.blood.cells.log,3)+
#                      Sedimentation.rate.log+Serum.Albumin+Serum.Cholesterol.log+ ns(Serum.Iron.sqrt,6)+ns(Serum.Magnesium,3)+ns(Serum.Protein,3)+
#                      Sex+ns(Systolic.BP,4)+TIBC+TS+White.blood.cells.log+ns(BMI.log,4)+ns(Pulse.pressure.sqrt,3) ,family = binomial, data = survey_mice)

```

We should consider the correlation between variables. According to heatmap made we have variables that are highly corralted such as `Systolic.BP`, `Diastolic.BP`,`PressurePulse`. In this case we can have an issue of collinearity to take into account. We can test it using VIF(Variance Inflation factor). The smallest value for VIF is 1, which indicates complete absence of multicollinearity. As a rule of thumb, a VIF vaue that exceeds 5 or 10 indicates a problematic amount of collinearity.

```{r}
# vif_values <- vif(fit.multi.lrm)
# vif_values
# 
# fit.multi.glm %>%
#   tbl_regression(exponentiate = TRUE) %>%
#   bold_labels() %>%
#   bold_p %>%
#   add_vif() #adjusted GVIF should be < 2
```

As we expected there is a problem of collinearity between three measurements referred to blood pressure. Let's drop out of `Systolic.BP` and `TS` since have the greatest VIF.
Then compare the model with `ANOVA`, where $H_0$ indicates that simpler model is better.

```{r}
#removed predictor with highest VIF: TS
# fit.multi.glm_ts<-glm(death ~ Age+ns(Diastolic.BP,4)+ns(Poverty.index.sqrt,3)+Race+ ns(Red.blood.cells.log,4)+
#                      Sedimentation.rate.log+Serum.Albumin+Serum.Cholesterol.log+ ns(Serum.Iron.sqrt,6)+ns(Serum.Magnesium,3)+Serum.Protein+
#                      Sex+ns(Systolic.BP,4)+TIBC+White.blood.cells.log+ns(BMI.log,4)+ns(Pulse.pressure.sqrt,3) ,family = binomial, data = survey_mice)
# 
# fit.multi.glm_ts
# anova( fit.multi.glm_ts, fit.multi.glm, test="LRT")
# # Log likelihood ratio test: H_0 simpler model captuers variance better, keep it, H_a prefer more complex model
# #If the resulting p-value is sufficiently low (usually less than 0.05), we conclude that the more complex model 
# #is significantly better than the simpler model
 
```

According to test (ANOVA, smaller AIC) we should consider the simpler model.

Considering ANOVA results, reduction in AIC, VIF and statistical significance of coefficients I ended up with this model, that is the full model without `Systolic.BP`, `TS`, `Race`.
```{r}
# fit.multi.glm_res<-glm(death ~ Age+ns(Diastolic.BP,4)+ns(Poverty.index.sqrt,3)+ns(Red.blood.cells.log,4)+
#                      Sedimentation.rate.log+Serum.Albumin+Serum.Cholesterol.log+ ns(Serum.Iron.sqrt,6)+ns(Serum.Magnesium,3)+ns(Serum.Protein,3)+
#                      Sex+TIBC+White.blood.cells.log+ns(BMI.log,4)+ns(Pulse.pressure.sqrt,3) ,family = binomial, data = survey_mice)
# 
# anova( fit.multi.glm_ts, fit.multi.glm, test="LRT")
# 
# fit.multi.lrm_res<-lrm(death ~ Age+Poverty.index.sqrt+rcs(Red.blood.cells.log,4)+
#                      Sedimentation.rate.log+Serum.Albumin+Serum.Cholesterol.log+ rcs(Serum.Iron.sqrt,6)+I(Serum.Magnesium^2)+Serum.Protein+
#                      Sex+TIBC+White.blood.cells.log+rcs(BMI.log,3)+Pulse.pressure.sqrt^2 ,data = survey_mice, y=T, x=T)
# summary(fit.multi.lrm_res)
# fit.multi.lrm_res
# anova(fit.multi.lrm_res)
```


### Backward algorithm: `fastbw()`
```{r}
#### BACKWARD ELIMINATION ALGORITHM
# fastbw(fit.multi.lrm)
# 
# #After several tests redcing the non linearity of Poverty and Iron we obtain a better model
# fit.bw1<- lrm(death~Age+ Poverty.index.sqrt+rcs(Red.blood.cells.log,3)+
#                 Sedimentation.rate.log+Serum.Albumin+rcs(Serum.Magnesium,3)+Systolic.BP+Serum.Protein+Sex+rcs(BMI.log,3)+
#                 rcs(Serum.Iron.sqrt,6)+White.blood.cells.log, data = survey_mice, y = TRUE, x=TRUE)
# fit.bw1
```



## Univariable filtering
```{r}

# #Consider the predictor statistically significant with p < 0.05 from the univariate models
# predictor <- c("Age", "Diastolic.BP", "Poverty.index.sqrt",
#                "Sedimentation.rate.log","Serum.Albumin", "Serum.Cholesterol.log", "Serum.Iron.sqrt ","Serum.Magnesium",
#                "Sex", "Systolic.BP","White.blood.cells.log", "Pulse.pressure.sqrt")
# 
# fit.univ<-lrm(death ~ rcs(Diastolic.BP,4)+rcs(Systolic.BP,4)+Age+rcs(Poverty.index.sqrt,3)+
#                 Sedimentation.rate.log+Serum.Albumin+Serum.Cholesterol.log+ rcs(Serum.Iron.sqrt,6)+ rcs(Serum.Magnesium,3)+
#                 Sex+White.blood.cells.log+rcs(Pulse.pressure.sqrt,3) ,data = survey_mice, y=T, x=T)
# fit.univ
# fit.univ2<-lrm(death ~ rcs(Diastolic.BP,4)+Age+rcs(Poverty.index.sqrt,3)+
#                 Sedimentation.rate.log+Serum.Albumin+Serum.Cholesterol.log+ rcs(Serum.Iron.sqrt,6)+ rcs(Serum.Magnesium,3)+
#                 Sex+White.blood.cells.log ,data = survey_mice, y=T, x=T)
# fit.univ2
```

## Forward algorithm
```{r }
# nothing <- glm(death~1, family=binomial, data = survey_mice)
# forwards <- step(nothing, scope=list(lower = formula(nothing),upper = formula(fit.multi.glm)),
#                  direction ="forward",trace=FALSE )
# 
# 
# #lrm model to compare with other
# fit.for<-lrm(death ~ Age + Sex + rcs(Poverty.index.sqrt, 4) + Sedimentation.rate.log + 
#     White.blood.cells.log + rcs(Red.blood.cells.log, 3) + rcs(Systolic.BP,4) + rcs(BMI.log, 4) + 
#       rcs(Serum.Magnesium, 3) + rcs(Serum.Iron.sqrt, 
#     6) + Serum.Albumin + rcs(Serum.Protein, 3) + TIBC, data = survey_mice, x=T, y=T)
# fit.for
# summary(fit.for)
```

## Bacward and forward
```{r}
# bothways <- step(nothing, list(lower=formula(nothing), upper = formula(fit.multi.glm)), 
#                  direction = "both", trace = 0)
# fit.both<-(death ~ Age + Sex + Sedimentation.rate.log + rcs(Poverty.index.sqrt, 4) + 
#              White.blood.cells.log + rcs(Systolic.BP, 4) + rcs(BMI.log, 4) + rcs(Serum.Magnesium,3) 
#            + rcs(Serum.Iron.sqrt, 6) + rcs(Red.blood.cells.log, 4) + Serum.Albumin + 
#              Serum.Protein + TIBC)
# #same as forward
```

```{r echo = FALSE}
############################## predictors effects on the logit scale
# 
# ggplot(Predict(fit.multi.lrm))
# ggplot(Predict(fit.multi.lrm_res))
# ggplot(Predict(fit.bw1))
# ggplot(Predict(fit.for))
# 
# 
# ########################### effects on odds ratio scale
# plot(summary(fit.multi.lrm),log=TRUE)
# plot(summary(fit.multi.lrm_res),log=TRUE)
# plot(summary(fit.bw1),log=TRUE)
# plot(summary(fit.for),log=TRUE)
# plot(summary(fit.for2),log=TRUE)
# plot(summary(fit.univ),log=TRUE)
# plot(summary(fit.univ2),log=TRUE) # SE e CI are reduced since we removed Systolic
```

## Models' performance

```{r}
# ######################## Performance statistics
# s <- fit.multi.lrm$stats # performance of the estimated model 
# round(s, digits=3) # C is the AUC and Dxy is related to C (Dxy=2*(C-0.5)), are both discrimination measures
# 
# gamma.hat <-  (s['Model L.R.'] - s['d.f.'])/s['Model L.R.'] #shrinkage coefficient
# 
# 
# s1 <- fit.multi.lrm_res$stats # performance of the estimated model 
# round(s1, digits=3) # C is the AUC and Dxy is related to C (Dxy=2*(C-0.5)), are both discrimination measures
# 
# gamma.hat1 <-  (s1['Model L.R.'] - s1['d.f.'])/s1['Model L.R.'] #shrinkage coefficient
# 
# #For both model C is equal 0.858, in the simpler model Dxy is slightly worse (from 0.717 to
# # 0.715). But the shrinkage coedfficient increases (from 0.980 to 0.985)
# 
# s2 <- fit.bw1$stats # performance of the estimated model 
# round(s2, digits=3)
# 
# gamma.hat2 <-  (s2['Model L.R.'] - s2['d.f.'])/s2['Model L.R.'] #shrinkage coefficient
# 
# s3 <- fit.for$stats # performance of the estimated model 
# round(s3, digits=3) 
# 
# gamma.hat3 <-  (s3['Model L.R.'] - s3['d.f.'])/s3['Model L.R.'] #shrinkage coefficient
# 
# s4 <- fit.univ$stats # performance of the estimated model 
# round(s4, digits=3) 
# 
# gamma.hat4 <-  (s4['Model L.R.'] - s4['d.f.'])/s4['Model L.R.'] #shrinkage coefficient
# 
# s5 <- fit.univ2$stats # performance of the estimated model 
# round(s5, digits=3) 
# 
# gamma.hat5 <-  (s5['Model L.R.'] - s5['d.f.'])/s5['Model L.R.'] #shrinkage coefficient

```


# Question 5: Model Discrimination and Evaluation

```{r comment=FALSE}
# Let us now use the bootstrap to further evaluate calibration and discrimination of this reduced model: 
# ## Full model
# fmult <- update(fit.multi.lrm , x=TRUE , y=TRUE)
# vmult <- validate (fmult, B=200)
# #vmult # Dxy (0,7167 to 0.7049) (opt 0.0118) Slope (1-0.9629) (opt  0.0371)
# cal.full  <- calibrate(fmult, B=200)
# 
# 
# ## Hand bw model
# vhand <- validate (fit.multi.lrm_res, B=200)
# #vhand             # Dxy 0.7093-0.7032 (opt 0.0061), slope 1 -0.9798 (opt 0.0202)
# cal.hbw <- calibrate(fit.multi.lrm_res, B=200)
# 
# 
# 
# ## Bw model
# #fhand <- update(fit.multi.lrm_res, x=TRUE , y=TRUE)
# vbw <- validate (fit.bw1, B=200)
# #vbw  # Dxy(0.7136-0.7070) opt(0.0066) slope(1-0.9791) (opt 0.0209)
# cal.bw <- calibrate(fit.bw1, B=200)
# 
# 
# 
# ## forward model
# ffor <- update(fit.for, x=TRUE , y=TRUE)
# vfor <- validate (ffor, B=200)
# #vfor  # Dxy(0.7141-0.7063) opt(0.0077) slope(1-0.9737) (opt 0.0263)
# cal.for <- calibrate(ffor, B=200)
# 
# 
# ## univariate model
# funiv <- update(fit.univ, x=TRUE , y=TRUE)
# vuniv <- validate (funiv, B=200)
# #vuniv  # Dxy( 0.7078-0.7000) opt(0.0078) slope(1-0.9753) (opt 0.0247)
# cal.univ <- calibrate(funiv, B=200)
# 
# 
# ## univariate reduced model
# funiv2 <- update(fit.univ2, x=TRUE , y=TRUE)
# vuniv2 <- validate (funiv2, B=200)
# #vuniv2  # Dxy(0.7048- 0.6999) opt(0.0049) slope(1-0.9838) (opt 0.0162)
# cal.univ2 <- calibrate(funiv2, B=200)

```

## Discrimination: AUC

```{r echo = FALSE}
# we could also make a test to compare the two models in terms of AUC: note that in the reduced model we have less missing values (in any case the % of missing values in this dataset is quite irrelevant)

source(".\\ROC.s\\summary.roc.s")
source(".\\ROC.s\\intersect.roc.s")
source(".\\ROC.s\\plot.roc.s")
source(".\\ROC.s\\print.roc.s")
source(".\\ROC.s\\roc.s")
source(".\\ROC.s\\print.summary.roc.s")
source(".\\ROC.s\\lroc2.r")

```


```{r  fig.width=15,fig.height=8,comment = FALSE, warning=FALSE}
# predicted probability by model

# full.pred  <- predict(fit.multi.lrm, type="fitted") 
# red.pred   <- predict(fit.multi.lrm_res, type="fitted") 
# bw.pred   <- predict(fit.bw1, type="fitted") 
# for.pred   <- predict(fit.for, type="fitted")
# univ.pred<-predict(fit.univ, type="fitted")
# univ.pred2<-predict(fit.univ2, type = "fitted")
# 
# dati.pp <- data.frame(survey_mice, full.pred, red.pred, bw.pred, for.pred, univ.pred, univ.pred2)
# dati.pp$Race <- as.numeric(dati.pp$Race)
# dati.pp$Sex <- as.numeric(dati.pp$Sex)
# dati.pp$death <- as.numeric(dati.pp$death)
# dati.pp$death <- dati.pp$death -1
# 
# 
# ###### compare FULL model and BACKWARD BY HAND model
# dati.pp<-select(dati.pp, -c("systolic_test", "status"))
# roc.comp <- roc(death ~ full.pred+red.pred, data = dati.pp)
# summary.roc(roc.comp) 
# # there is evidence that the 2 curves are statistically different.
# 
# par(pty="s")
# model0 <- glm(death ~ full.pred, data = dati.pp, family=binomial)
# lroc0  <- lroc2(model0,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="black")
# model1 <- glm(death ~ red.pred, data = dati.pp, family=binomial)
# plot.new
# lroc1 <- lroc2(model1,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="red")
# legend("bottomright", legend=c("Full Model","Hand Backward"), col=c("black", "red"), lty=c(1,1), bty="n")
# # Indeed the plot shows no difference between the 2 curves
# 
# #### compare FULL model and BACKWARD BY ALGORITHM
# 
# roc.comp2 <- roc(death ~ full.pred+bw.pred, data = dati.pp)
# summary.roc(roc.comp2) # little evidence of difference between the 2 curves, the full model is more discriminative,
# # however the 2 curves are comparable
# # but full model is less calibrate
# par(pty="s")
# lroc0  <- lroc2(model0,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="black")
# model3 <- glm(death ~ bw.pred, data = dati.pp, family=binomial)
# plot.new
# lroc3 <- lroc2(model3,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="red")
# legend("bottomright", legend=c("Full Model","Backward Model"), col=c("black", "red"), lty=c(1,1), bty="n")
# 
# #### compare BACKWARD BY HAND and BACKWARD BY ALGORITHM
# roc.comp3 <- roc(death ~ red.pred+bw.pred, data = dati.pp)
# summary.roc(roc.comp3) # little evidence of difference: backward by hand more discriminative
# 
# par(pty="s")
# lroc4  <- lroc2(model1,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="black")
# model5 <- glm(death ~ bw.pred, data = dati.pp, family=binomial)
# plot.new
# lroc5 <- lroc2(model5,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="red")
# lroc5$auc
# legend("bottomright", legend=c("Bw hand","Bw algorithm"), col=c("black", "red"), lty=c(1,1), bty="n")
# 
# 
# # comparison of 3 models
# par(pty="s")
# model0 <- glm(death ~ full.pred, data = dati.pp, family=binomial)
# lroc0  <- lroc2(model0,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="black")
# model2 <- glm(death ~ red.pred, data = dati.pp, family=binomial)
# plot.new
# lroc22 <- lroc2(model2,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="red")
# model22 <- glm(death ~ bw.pred, data = dati.pp, family=binomial)
# plot.new
# lroc222 <- lroc2(model22,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="blue")
# legend("bottomright", legend=c("Full Model","Bw by hand", "bw by algorithm"), col=c("black", "blue", "red"), lty=c(1,1,1), bty="n")
# # all the three models are comparable in terms of discriminative ability, but the backward model are more calibrate
# # since are more parsimonious.
# 
# #### compare FORWARD  model and BACKWARD BY ALGORITHM
# 
# roc.comp4 <- roc(death ~ for.pred+bw.pred, data = dati.pp)
# summary.roc(roc.comp4) # no evidence of difference
# 
# # comparison of 4 models
# par(pty="s")
# model0 <- glm(death ~ full.pred, data = dati.pp, family=binomial)
# lroc0  <- lroc2(model0,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="black")
# model2 <- glm(death ~ red.pred, data = dati.pp, family=binomial)
# plot.new
# lroc22 <- lroc2(model2,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="red")
# model22 <- glm(death ~ bw.pred, data = dati.pp, family=binomial)
# plot.new
# lroc222 <- lroc2(model22,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="blue")
# model23 <- glm(death ~ for.pred, data = dati.pp, family=binomial)
# plot.new
# lroc23 <- lroc2(model23,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="green")
# model5 <- glm(death ~ univ.pred, data = dati.pp, family=binomial)
# plot.new
# lroc5 <- lroc2(model5,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="purple")
# model6 <- glm(death ~ univ.pred2, data = dati.pp, family=binomial)
# plot.new
# lroc6 <- lroc2(model6,add=T,lty.choice=1,lwd=1,pch='.',cex=0.1,line.col="orange")
# legend("bottomright", legend=c("Full Model","Bw by hand", "bw by algorithm", "forward", "univ", "univ_red"), col=c("black", "blue", "red","green", "purple", "orange"), lty=c(1,1,1), bty="n")
# 
# # all the three models are comparable in terms of discriminative ability, but the backward model are more calibrate
# # since are more parsimonious.
# 
# # Backward by hand and bw by algorithm seem to be the best models. Their disriminative ability is very close to 
# # the one of the full model, AIC smaller and are more calibrate
# ```
 
 
## Summary: Multivariable Model chosen
```

```{r fig.width=15,fig.height=10}

# 
# #### Calibration
# par(mfrow = c(2,3))
# plot(cal.full, main = "Full model") # MAE 0.004
# plot(cal.hbw,main = "Bw by hand") # MAE 0.004
# plot(cal.bw, main = "Bw by algorithm") #MAE = 0.003
# plot(cal.for, main = "Forward by algorithm") #MAE = 0.003 -> fit.for.s has a better calibration (MAE=0.03)
# plot(cal.univ, main = "Univariate Filtering") #MAE = 0.003
# plot(cal.univ2, main = "Univariate Filtering reduced") #MAE = 0.003
# 
# 
# col<-c("full", "hand_bw", "bw","forward", "univ", "univ_red")
# 
# #### Shrinkage
# gamma.t <- c(gamma.hat, gamma.hat1, gamma.hat2, gamma.hat3, gamma.hat4, gamma.hat5) 
# # univ_red is the better,indicating that this model will validate 
# #on new data about 1% worse than on this dataset (simpler than the full model, less overfitting).
# 
# m <- matrix(gamma.t, nrow = 1, byrow = TRUE, 
#             dimnames = list("Shrink", col))
# m
# 
# #### AIC
# AIC.models <- c(AIC(fit.multi.lrm), AIC(fit.multi.lrm_res), AIC(fit.bw1), AIC(fit.for), AIC(fit.univ), AIC(fit.univ2))
#  
# 
# mAIC <- matrix(AIC.models, nrow = 1, byrow = TRUE, 
#             dimnames = list("AIC", col))
# mAIC # forward is the better
# 
# #### AUC
# area <- c(lroc0$auc, lroc22$auc, lroc222$auc, lroc23$auc, lroc5$auc, lroc6$auc) 
# 
# mAuc <- matrix(area, nrow = 1, byrow = TRUE, 
#             dimnames = list("AUC", col))
# mAuc
```

Considering all the results returned by different statistical procedures we can conclude that all the models are very close in term of discrimination and calibration. The best trade-off between this two measures is given by `fit.bw1`, that is the model obtained by the algorithm `fastbw()` removing the non linear effect of `Poverty.index.sqrt` (as suggested by `anova` and by p-value of coefficients).

```{r}
# fit.bw1
# confint.default(fit.bw1)
```


We have to keep in mind that coefficients $\Beta$ in logistic regression represents the change in the log odds when the predictors inscreasing by one unit.
In order to interpret the results it easier reasoning on the Odds Ratio scale. The Odds ratio is a measure of association between the predictor and the outcome:

- OR > 1 indicates an increase of the probability of the outcome 
- OR = 1 indicates a zero effect of the predictor on the probability of the outcome
- 0R > 1 means that predictor has a protective effect, decreases the probbability of the outcome.

If the predictor is **continous** and we exponentiate its coefficient estimated by the model we obtain the estimate of OR for an increase of one unit of the predictor keeping all the other covariates constant, while from `summary(model)` we obtain the effect in an interquartile range.
If the predictor is **binary or categorical** we obtain the estimate of OR of a level with respect to the chosen baseline level.

```{r fig.width=10,fig.height=6}
#Age
# exp(fit.bw1$coefficients)[2]
# 
# ### Effect on odds ratio scale
# # Interquartile-range odds ratios for continuous predictors and simple odds
# # ratios for categorical predictors. Numbers at left are upper quartile vs lower quartile or
# # current group vs reference group. The bars represent confidence limits.
# # The intervals are drawn on the log odds ratio scale and labeled on the odds ratio
# # scale. Ranges are on the original scale.
# summary(fit.bw1)
# plot(summary(fit.bw1),log=TRUE)
# anova(fit.bw1)

```

From this model we have a protective effect on the risk of death for :`Poverty.index.sqrt`, `BMI.log`, `Serum.Albumin`, `Serum.Magnesium`, `BMI.log`.
For example for `Poverty.index.sqrt` means that being richer decreases the risk of death.

We have to be aware that for the value trnsformed we have to apply exp() or power of 2 if we use log or sqrt respectively. For example we have that patients with Poverty index of $(19,3)^2$(136) have 25% less risk to death than patient with index $11,7 (361).

On the contrary the probability of death is increased by the predictors `Age`, `Sedimentation.rate.log`, `Systolic.BP`, `Serum. Protein`, `White.blood.cell`. This means that the increase of this predictors increses the risk of death.
Furthermore it results that `male` subjects seem to have a 2.85 times higher risk than `female` ones.


# Question 6: Present the results
**Represent for the clinical audience the results from the estimated model**
```{r fig.width=15,fig.height=12}
# survey_mice$Sexf <- as.factor(survey_mice$Sex)
# levels(survey_mice$Sexf)   <- c("male","female")
# label(survey_mice$Sexf)    <- "Sex"
# 
# options(datadist='dd')
# dd <-datadist(survey_mice)
# formula(fit.bw1)
# 
# fredfin <- lrm(death ~ Age + Poverty.index.sqrt + rcs(Red.blood.cells.log, 3) + Sedimentation.rate.log + 
#     Serum.Albumin + rcs(Serum.Magnesium, 3) + Systolic.BP + Serum.Protein + 
#     Sex + rcs(BMI.log, 3) + rcs(Serum.Iron.sqrt, 6) + White.blood.cells.log ,data = survey_mice)
# fredfin
# 
# 
# nom <-  nomogram (fredfin,
#                   fun=plogis , funlabel ="Probability ",
#                   lp=TRUE, 
#                   fun.at =c(.01,.1,.25,.5,.75,.95))
# 
# 
# plot(
#   nom,
#   cex.axis = 0.85 ,
#   cex.var = 0.85 ,
#   #col.grid = gray(c(0.8, 0.95))
#   )
# 
# 
# nom

```

# Question 7: Machine Learning model XGBoost

Why?
XGBoost is an algorithm that has recently been dominating applied machine learning competitions, also in biomedical research. It has a wide range of applications: Can be used to solve regression, classification, ranking, and user-defined prediction problems. 
XGBoost stands for eXtreme Gradient Boosting and is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. **Gradient Boosting** specifically is an approach where new models are trained to predict the residuals (i.e errors) of prior models. Iteratively a new tree is built to predict the residual errors of the previous tree, which are then combined with previous tree for final predictions (Boosting). When adding new models the losses is minimized using gradient descent algorithm.

```{r}
survey_mice$death <- as.factor(survey_mice$death)

#split data in train and test set
# splitting assuring that outcome distribution is equal in both train and test

trainIndex <- createDataPartition(survey_mice$death, p = .8, 
                                  list = FALSE, 
                                  times = 1)
surveyTrain <- survey_mice[ trainIndex,]
surveyTest  <- survey_mice[-trainIndex,]

options(na.action='na.pass')

#implement one hot encoding: all the variables must be numeric
new.tr <- model.matrix(~., data = surveyTrain %>% dplyr::select(-c(death, time_death, status))) 

options(na.action='na.pass')
new.ts <- model.matrix(~., data = surveyTest %>% dplyr::select(-c(death, time_death, status)))

#convert factor response to numeric
train.labels = as.numeric(surveyTrain$death)-1
test.labels = as.numeric(surveyTest$death)-1

dtrain <- xgb.DMatrix(data = new.tr, label = train.labels) 
dtest <- xgb.DMatrix(data = new.ts, label = test.labels)

#tuning parameter
# gbtree = ensemble of decision trees
params <- list(booster = "gbtree", objective = "binary:logistic", eta=0.3, gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1)

xgbcv <- xgb.cv( params = params, data = dtrain, nrounds = 100, nfold = 5, showsd = T,
                 stratified = T,print_every_n = 10, early_stopping_rounds = 20, maximize = F, metrics = "auc", prediction = T)

xgbcv_er <- xgb.cv( params = params, data = dtrain, nrounds = 100, nfold = 5, showsd = T,
                 stratified = T,print_every_n = 10, early_stopping_rounds = 20, maximize = F, metrics = "error", prediction = T)

xgbcv_er <- xgb.cv( params = params, data = dtrain, nrounds = 100, nfold = 5, showsd = T,
                 stratified = T,print_every_n = 10, early_stopping_rounds = 20, maximize = F, metrics = "mae", prediction = T)


xgbcv_er

# model training
xgb1 <- xgb.train (params = params, data = dtrain, nrounds = 79, watchlist = list(val=dtest,train=dtrain),
                     print_every_n = 10, early_stopping_round = 10, maximize = F , eval_metric = "error")

#model prediction
xgbpred <- predict (xgb1,dtest)
test.labels<-as.factor(test.labels)

xgbpredC <- ifelse (xgbpred > 0.5,1,0)
xgbpredf<-as.factor(xgbpredC)
test.labelsf<-as.factor(xgbpred)
confusionMatrix(xgbpredf, test.labels)
test.labelsf
MAE(test.labels, xgbpred)


#Importance of variables
mat <- xgb.importance (feature_names = colnames(new.tr),model = xgb1)
xgb.ggplot.importance (importance_matrix = mat[1:19]) 

cal_plot <- calibration(test.labels ~ xgbpred, data = survey_mice, class = 1)
plot(cal_plot, xlab("Predicted Probability"))
```

This ML algorithm perform very well on the test set, it correctly classify all the patients. 
But if we evaluate its performance by means of **5-folds cross-validation** we see that it is comparable to the Logistic Regression model implemented. The **AUC** measure, indeed, is **~80%**.

The list of most important variables returned reflects partially the ones used in the Logistic model. Both identified `Age` as the main contributor.

We have to consider that ML algorithm works very well on large and complex dataset and this could be a limitations when we deal with medical data.


# Comments and Further extension

- The log and sqrt transformation of some variables in order to make them more normally distribution leads to smaller SE

- The Logistic model perform quite well with an AUC > 80%

- We could try to stratify data by Sex to see if there are any differences between groups

- We have highly correlated variables and this could impact the goodness of fit neverthless the estimate of coefficients. Dropping the most correlated variables is the easiest solution but not the most effective. There could be important interactions and thus possible cofounding variables not considered in this model. A clinician opinion could be useful to consider these intractions
















